# Crypto Analytics Platform ğŸ“Š

A real-time quantitative analytics platform for cryptocurrency pairs trading, featuring live WebSocket data ingestion, statistical analysis, and interactive visualization.

## ğŸ¯ Features

- **Real-time Data Ingestion**: Live tick data from Binance WebSocket streams
- **Multi-Timeframe Analysis**: 1-second, 1-minute, and 5-minute OHLC resampling
- **Quantitative Analytics**:
  - Price statistics and VWAP
  - OLS regression for hedge ratios
  - Spread calculation and z-score analysis
  - ADF test for cointegration
  - Rolling correlation metrics
- **Interactive Dashboard**: Streamlit-based UI with Plotly charts
- **Alert System**: Custom rule-based alerts for trading signals
- **Data Export**: CSV export functionality for processed data
- **Historical Data Upload**: Support for OHLC CSV uploads

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Binance WSS    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  WebSocket      â”‚
â”‚  Ingestion      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Database       â”‚â—„â”€â”€â”€â”€â”¤  Resampling     â”‚
â”‚  (SQLite/       â”‚     â”‚  Engine         â”‚
â”‚   PostgreSQL)   â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Analytics      â”‚â—„â”€â”€â”€â”€â”¤  Cache Layer    â”‚
â”‚  Engine         â”‚     â”‚  (Redis/Memory) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI        â”‚
â”‚  REST API       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Streamlit      â”‚â—„â”€â”€â”€â”€â”¤  Alert Manager  â”‚
â”‚  Dashboard      â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Prerequisites

- Python 3.9 or higher
- pip package manager
- (Optional) PostgreSQL/TimescaleDB for production deployment
- (Optional) Redis for caching

## ğŸš€ Quick Start

### 1. Clone and Navigate

```bash
cd "c:\Users\pisep\OneDrive\Desktop\6th sem main\Projects\Gemscap"
```

### 2. Create Virtual Environment

```bash
python -m venv venv
.\venv\Scripts\Activate.ps1  # Windows PowerShell
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Configure Environment

```bash
copy .env.example .env
# Edit .env with your configuration (optional)
```

### 5. Run the Application

```bash
python run.py
```

This will:

- Initialize the database
- Start the FastAPI backend (http://localhost:8000)
- Launch the Streamlit dashboard (http://localhost:8501)
- Begin ingesting live data from Binance

## ğŸ“ Project Structure

```
Gemscap/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ ingestion/          # WebSocket clients and data sampling
â”‚   â”œâ”€â”€ storage/            # Database models and connections
â”‚   â”œâ”€â”€ analytics/          # Quantitative analysis modules
â”‚   â”œâ”€â”€ api/                # FastAPI routes and endpoints
â”‚   â””â”€â”€ alerts/             # Alert management system
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ components/         # Streamlit UI components
â”‚   â””â”€â”€ utils/              # Frontend utilities
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py         # Configuration management
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.drawio # System architecture diagram
â”‚   â””â”€â”€ chatgpt_usage.md    # AI assistance documentation
â”œâ”€â”€ tests/                  # Unit and integration tests
â”œâ”€â”€ logs/                   # Application logs
â”œâ”€â”€ exports/                # Exported data files
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ .env.example            # Environment template
â”œâ”€â”€ run.py                  # Application launcher
â””â”€â”€ README.md               # This file
```

## ğŸ”§ Configuration

Key configuration options in `.env`:

| Variable                 | Default                           | Description                  |
| ------------------------ | --------------------------------- | ---------------------------- |
| `DEBUG`                  | `True`                            | Enable debug mode            |
| `API_PORT`               | `8000`                            | FastAPI port                 |
| `FRONTEND_PORT`          | `8501`                            | Streamlit port               |
| `DATABASE_URL`           | `sqlite:///./crypto_analytics.db` | Database connection          |
| `REDIS_ENABLED`          | `False`                           | Enable Redis caching         |
| `DEFAULT_SYMBOLS`        | `["BTCUSDT","ETHUSDT"]`           | Trading pairs to monitor     |
| `DEFAULT_ROLLING_WINDOW` | `20`                              | Rolling window for analytics |

## ğŸ“Š Analytics Methodology

### Pairs Trading Analytics

1. **Hedge Ratio Calculation**: OLS regression between two assets

   - `Y = Î± + Î²*X + Îµ`
   - Hedge ratio = Î² (slope coefficient)

2. **Spread Construction**: `Spread = Price_A - (HedgeRatio Ã— Price_B)`

3. **Z-Score Normalization**:

   - `Z = (Spread - Î¼) / Ïƒ`
   - Rolling mean (Î¼) and std (Ïƒ) over configurable window

4. **Cointegration Test**: Augmented Dickey-Fuller (ADF) test

   - H0: Spread has unit root (not cointegrated)
   - p-value < 0.05 suggests cointegration

5. **Rolling Correlation**: Pearson correlation coefficient over rolling window

## ğŸ¨ Dashboard Usage

### Main Controls

- **Symbol Selection**: Choose trading pairs for analysis
- **Timeframe**: Select data granularity (1s, 1m, 5m)
- **Rolling Window**: Adjust window for moving statistics
- **Analytics Options**: Enable/disable specific calculations

### Visualizations

- **Price Charts**: Interactive candlestick/line charts with zoom/pan
- **Spread & Z-Score**: Pairs trading signals
- **Correlation Heatmap**: Cross-asset relationships
- **Volume Analysis**: Trading activity metrics
- **Statistics Table**: Real-time summary metrics

### Alerts

Configure custom alerts:

- Z-score thresholds
- Price level breakouts
- Correlation breakdowns
- Volume spikes

## ğŸ“¤ Data Export

Export processed data and analytics:

1. Navigate to Export section in dashboard
2. Select date range and metrics
3. Click "Download CSV"
4. Files saved to `exports/` directory

## ğŸ§ª Testing

Run tests:

```bash
pytest tests/
```

Run specific test:

```bash
pytest tests/test_analytics.py
```

## ğŸ› Troubleshooting

### Database Issues

```bash
# Reset database
python -c "from backend.storage.database import init_db, engine; from backend.storage.models import Base; Base.metadata.drop_all(engine); init_db()"
```

### Port Already in Use

- Change `API_PORT` or `FRONTEND_PORT` in `.env`

### WebSocket Connection Fails

- Check internet connection
- Verify Binance API is accessible
- Review logs in `logs/app.log`

## ğŸ“ Development Notes

### Adding New Analytics

1. Create module in `backend/analytics/`
2. Inherit from `BaseAnalyzer` class
3. Implement `calculate()` method
4. Register in analytics engine

### Adding New Alerts

1. Define alert type in `backend/alerts/rules.py`
2. Implement condition logic
3. Update frontend alert configuration

## ğŸ¤– AI Assistance

This project utilized ChatGPT/Claude for:

- Code structure and boilerplate generation
- Analytics algorithm implementation
- Documentation writing
- Debugging assistance

See `docs/chatgpt_usage.md` for detailed prompt logs.

## ğŸ“„ License

This project is for educational and evaluation purposes.

## ğŸ‘¤ Author

**Anagh**  
Quant Developer Evaluation Assignment

## ğŸ™ Acknowledgments

- Binance for WebSocket API
- Streamlit for rapid dashboard development
- FastAPI for modern API framework
- Open-source Python scientific computing stack

---

**Note**: This is a prototype system designed for demonstration purposes. For production deployment, consider:

- Horizontal scaling with message queues (Kafka/RabbitMQ)
- TimescaleDB for time-series optimization
- Kubernetes for container orchestration
- Monitoring and alerting (Prometheus/Grafana)
- Authentication and authorization
- Rate limiting and API security
